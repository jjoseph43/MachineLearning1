{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24237f4a",
   "metadata": {},
   "source": [
    "You are to build upon the predictive analysis (classification) that you already completed in the previous mini-project, adding additional modeling from new classification algorithms as well as more explanations that are inline with the CRISP-DM framework. You should use appropriate cross validation for all of your analysis (explain your chosen method of performance validation in detail). Try to use as much testing data as possible in a realistic manner (you should define what you think is realistic and why).\n",
    "This report is worth 20% of the final grade. Please upload a report (one per team) with all code used, visualizations, and text in a single document. The format of the document can be PDF, *.ipynb, or HTML. You can write the report in whatever format you like, but it is easiest to turn in the rendered iPython notebook. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report.\n",
    "\n",
    "### Dataset Selection\n",
    "Select a dataset identically to the way you selected for the first project work week and mini-project. You are not required to use the same dataset that you used in the past, but you are encouraged. You must identify two tasks from the dataset to regress or classify. That is:\n",
    "- two classification tasks OR\n",
    "- two regression tasks OR\n",
    "- one classification task and one regression task\n",
    "\n",
    "For example, if your dataset was from the diabetes data you might try to predict two tasks: (1) classifying if a patient will be readmitted within a 30 day period or not, and (2) regressing what the total number of days a patient will spend in the hospital, given their history and specifics of the encounter like tests administered and previous admittance.\n",
    "\n",
    "### Grading Rubric\n",
    "\n",
    "#### Data Preparation (15 points total)\n",
    "- [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "\n",
    "### Modeling and Evaluation (70 points total)\n",
    "\n",
    "- [10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [10 points] Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [20 points] Create three different classification/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric.\n",
    "\n",
    "Logistic Regression FOR Injury and Phase - Satvik\n",
    "With grid search for both Injury and Phase - Satvik\n",
    "\n",
    "KNN FOR Injury and Phase - Nnenna\n",
    "With grid search for both Injury and Phase - Nnenna\n",
    "[Thursday]\n",
    "\n",
    "Random Forest FOR Injury and Phase - Jobin\n",
    "With grid search for both Injury and Phase - Jobin\n",
    "[Thursday]\n",
    "get feature importance - Jobin\n",
    "\n",
    "\n",
    "- [10 points] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "Dylan - Create table for 3 Injury grid search models and 3 Phase of flight grid search models \n",
    "-make more colorful confusion matrix\n",
    "[Thursday]\n",
    "\n",
    "- [10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods.\n",
    "\n",
    "Dylan - model advantages\n",
    "use package that Jake told us to use for statistical comparison -  Dylan\n",
    "\n",
    "- [10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "Random Forest has feature importance maybe use this\n",
    "\n",
    "### Deployment (5 points total)\n",
    "\n",
    "- [5 points] How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "Dylan\n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "\n",
    "YAY done kind of...\n",
    "\n",
    "- You have free reign to provide additional modeling.\n",
    "- One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fa961",
   "metadata": {},
   "source": [
    "# Lab Two: Classification\n",
    "\n",
    "Dylan Scott, Satvik Ajmera, Nnenna Okpara, Jobin Joseph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b612327",
   "metadata": {},
   "source": [
    "# NTSB Aviation Accident and Incident Data (NTSB)\n",
    "\n",
    "Source: https://data.ntsb.gov/avdata\n",
    "\n",
    "From the source, we will be using the NTSB data which consists of various attributes related to aviation accidents and incidents. This data includes incidents and accidents that have occured till date. \n",
    "\n",
    "The goal for this lab is to build two classification models that predict:\n",
    "\n",
    "1. Predicting if an incident/accident has resulted in an injury (binary classification)\n",
    "2. Predicting the phase of flight for an incident that has occured (multiclass classification)\n",
    "\n",
    "For this we will create two dataframes for these two classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b884cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce08fc6",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b9727",
   "metadata": {},
   "source": [
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "[5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef109db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115706 entries, 0 to 115705\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   acft_make          115643 non-null  object \n",
      " 1   acft_model         115630 non-null  object \n",
      " 2   cert_max_gr_wt     98673 non-null   float64\n",
      " 3   acft_category      115287 non-null  object \n",
      " 4   damage             113877 non-null  object \n",
      " 5   far_part           114925 non-null  object \n",
      " 6   afm_hrs_last_insp  60298 non-null   float64\n",
      " 7   type_fly           108599 non-null  object \n",
      " 8   dprt_state         108791 non-null  object \n",
      " 9   rwy_len            64222 non-null   float64\n",
      " 10  rwy_width          63110 non-null   float64\n",
      " 11  ev_type            115706 non-null  object \n",
      " 12  ev_city            115646 non-null  object \n",
      " 13  ev_state           109635 non-null  object \n",
      " 14  ev_country         115199 non-null  object \n",
      " 15  inj_f_grnd         51624 non-null   float64\n",
      " 16  inj_m_grnd         51543 non-null   float64\n",
      " 17  inj_s_grnd         51520 non-null   float64\n",
      " 18  inj_tot_f          64375 non-null   float64\n",
      " 19  inj_tot_m          63902 non-null   float64\n",
      " 20  inj_tot_n          90784 non-null   float64\n",
      " 21  inj_tot_s          60713 non-null   float64\n",
      " 22  inj_tot_t          79933 non-null   float64\n",
      " 23  sky_cond_ceil      104219 non-null  object \n",
      " 24  sky_cond_nonceil   100624 non-null  object \n",
      " 25  wx_int_precip      49898 non-null   object \n",
      " 26  phase_flt_spec     113882 non-null  object \n",
      "dtypes: float64(12), object(15)\n",
      "memory usage: 23.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read in the Aviation Data\n",
    "final_data = pd.read_csv(\"../Data/final_data.csv\",low_memory=False,dtype={'damage': str})\n",
    "#Delete columns that were imported incorrectly\n",
    "del final_data[\"Unnamed: 0\"]\n",
    "del final_data[\"dprt_state.1\"]\n",
    "del final_data[\"dprt_city\"]\n",
    "del final_data[\"index\"]\n",
    "del final_data[\"ntsb_no_x\"]\n",
    "del final_data['wind_vel_ind']\n",
    "del final_data[\"ev_id\"]\n",
    "del final_data['ev_highest_injury']\n",
    "\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e38e57",
   "metadata": {},
   "source": [
    "### 1a. Data Preparation for predicting Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395cfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the all empty values to Nan\n",
    "final_data= final_data.replace(r'^\\s+$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cb7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper case all factor levels for each categorical variable\n",
    "final_data['acft_make'] = final_data['acft_make'].str.upper()\n",
    "final_data['acft_category'] = final_data['acft_category'].str.upper()\n",
    "final_data['damage'] = final_data['damage'].str.upper()\n",
    "final_data['type_fly'] = final_data['type_fly'].str.upper()\n",
    "final_data['dprt_state'] = final_data['dprt_state'].str.upper()\n",
    "final_data['ev_city'] = final_data['ev_city'].str.upper()\n",
    "final_data['ev_type'] = final_data['ev_type'].str.upper()\n",
    "final_data['ev_city'] = final_data['ev_city'].str.upper()\n",
    "final_data['ev_country'] = final_data['ev_country'].str.upper()\n",
    "final_data['sky_cond_ceil'] = final_data['sky_cond_ceil'].str.upper()\n",
    "final_data['sky_cond_nonceil'] = final_data['sky_cond_nonceil'].str.upper()\n",
    "final_data['wx_int_precip'] = final_data['wx_int_precip'].str.upper()\n",
    "final_data['phase_flt_spec'] = final_data['phase_flt_spec'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb3d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.loc[final_data['damage'].str.contains('UNK', na=False), 'damage'] = 'UNK'\n",
    "\n",
    "#rename the injuries columns to make them easier to read\n",
    "final_data = final_data.rename(columns={\"inj_tot_f\": \"Total_Fatal_Injuries\", \n",
    "                                        \"inj_tot_s\":\"Total_Serious_Injuries\",\n",
    "                                        \"inj_tot_m\":\"Total_Minor_Injuries\",\n",
    "                                        \"inj_tot_n\":'Total_Uninjured',\n",
    "                                        \"inj_tot_t\":\"Total_Injuries_Flight\"})\n",
    "\n",
    "#fill in 0s when there wasn't an injury in that category\n",
    "final_data.update(final_data[['Total_Fatal_Injuries','Total_Serious_Injuries',\n",
    "                              'Total_Minor_Injuries','Total_Uninjured',\n",
    "                              'Total_Injuries_Flight','inj_f_grnd',\n",
    "                              'inj_m_grnd','inj_s_grnd']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa26f1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acft_make</th>\n",
       "      <th>acft_model</th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>acft_category</th>\n",
       "      <th>damage</th>\n",
       "      <th>far_part</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>type_fly</th>\n",
       "      <th>dprt_state</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>...</th>\n",
       "      <th>inj_s_grnd</th>\n",
       "      <th>Total_Fatal_Injuries</th>\n",
       "      <th>Total_Minor_Injuries</th>\n",
       "      <th>Total_Uninjured</th>\n",
       "      <th>Total_Serious_Injuries</th>\n",
       "      <th>Total_Injuries_Flight</th>\n",
       "      <th>sky_cond_ceil</th>\n",
       "      <th>sky_cond_nonceil</th>\n",
       "      <th>wx_int_precip</th>\n",
       "      <th>phase_flt_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>747-100</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>MINR</td>\n",
       "      <td>121</td>\n",
       "      <td>113.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>JA</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SCAT</td>\n",
       "      <td>UNK</td>\n",
       "      <td>LANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>172</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>091</td>\n",
       "      <td>40.0</td>\n",
       "      <td>PERS</td>\n",
       "      <td>UNK</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>LGT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>207</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>135</td>\n",
       "      <td>49.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AK</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>DESCENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acft_make            acft_model  cert_max_gr_wt  \\\n",
       "0  BOEING                          747-100                     750000.0   \n",
       "1  CESSNA                          172                           2300.0   \n",
       "2  CESSNA                          207                           3800.0   \n",
       "\n",
       "  acft_category damage far_part  afm_hrs_last_insp type_fly dprt_state  \\\n",
       "0          AIR    MINR     121               113.0     UNK          JA   \n",
       "1          AIR    SUBS     091                40.0     PERS        UNK   \n",
       "2          AIR    SUBS     135                49.0     UNK          AK   \n",
       "\n",
       "   rwy_len  ...  inj_s_grnd Total_Fatal_Injuries Total_Minor_Injuries  \\\n",
       "0  11800.0  ...         0.0                  0.0                  0.0   \n",
       "1   6398.0  ...         0.0                  0.0                  0.0   \n",
       "2   2610.0  ...         0.0                  0.0                  0.0   \n",
       "\n",
       "  Total_Uninjured Total_Serious_Injuries  Total_Injuries_Flight  \\\n",
       "0             4.0                    0.0                    0.0   \n",
       "1             1.0                    0.0                    0.0   \n",
       "2             1.0                    0.0                    0.0   \n",
       "\n",
       "   sky_cond_ceil  sky_cond_nonceil  wx_int_precip  phase_flt_spec  \n",
       "0           NONE              SCAT            UNK         LANDING  \n",
       "1            BKN               UNK            LGT         UNKNOWN  \n",
       "2            BKN               UNK            UNK         DESCENT  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.dropna(subset=['cert_max_gr_wt','afm_hrs_last_insp',\n",
    "                          'rwy_len','rwy_width'],inplace=True)\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "final_data.update(final_data.fillna(\"UNK\"))\n",
    "phase_df = final_data.copy()\n",
    "final_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4aac1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Injury\n",
       "0      1   18750\n",
       "1      0   16677"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to account for ALL injuries. This includes injuries on the ground as well as passangers\n",
    "#Here we will make a new column that shows total injuries including ground ones\n",
    "final_data['Total_Injuries_Ground'] = final_data['inj_f_grnd']+final_data['inj_m_grnd']+final_data['inj_s_grnd']\n",
    "final_data['Total_Injuries'] = final_data['Total_Injuries_Ground']+final_data['Total_Injuries_Flight']\n",
    "final_data['Injury'] = np.where(final_data['Total_Injuries'] >0,1,0)\n",
    "injuries = final_data[\"Injury\"].value_counts().reset_index()\n",
    "injuries.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a2367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_data.copy()\n",
    "#Since we added up all of our injuries we don't need the other columns that include injury count since it will be colinear to our prediction variable\n",
    "final_df = final_df.drop(['Total_Fatal_Injuries','Total_Serious_Injuries','Total_Minor_Injuries',\n",
    "                          'Total_Uninjured','Total_Injuries_Flight','inj_f_grnd','inj_m_grnd',\n",
    "                          'inj_s_grnd','Total_Injuries_Ground',\"Total_Injuries\"],axis = 1)\n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0886957",
   "metadata": {},
   "source": [
    "#### Preprocessing and Final Dataset description for Binary Classification: `Injury` \n",
    "\n",
    "We fixed the levels of columns that should have been grouped together for the `damage` predictor. We fixed the levels of the `ev_city`, by making all the city names uppercase so they would be grouped together. Then, we took the subset of the continuous predictors: `cert_max_gr_wt`,`afm_hrs_last_insp`,`rwy_len`, and `rwy_width` and removed all the NAs. We were left with approximately 35,000 rows that would be usable for prediction.\n",
    "\n",
    "The NTSB database allowed use to include ground injuries in addition to flight injuries. So we renamed the columns, replaced the NAs in these columns with 0 and summed all them to get a total injuries column. We wanted to only include the total injuries and drop the other types of injury columns. From there, we converted the total injuries column to a binary variable for classification. If the total injuries were greater than 1, it is considered injured and less than 1 is uninjured. Our last step was to impute all the NA's for the categorical values with an unknown value called `UNK` In all, we are left with the dataframe `final_df` which consisted of 21 columns and 35,427 observations. \n",
    "\n",
    "Of the total 35,427 observations, 18750 observations were reported as injured and 16677 were reported as uninjured. This column called `Injury` is the response variable, we would like to predict for the classification problem.\n",
    "\n",
    "Our final preprocess method was one-hot encoding our categorical variables. We did not standardize and scale continuous predictors. We did this, because standardizing and scaling some predictors may result in the loss of information. For example, there may be certain aircraft weights (cert_max_gr_wt) where that weight is important in classifying whether or not an incident/accident resulted in an injury.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a49d42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230439b",
   "metadata": {},
   "source": [
    "**Our final dataframe for classifying `Injury` is called `injury_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895911e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35427 entries, 0 to 35426\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   acft_make          35427 non-null  object \n",
      " 1   acft_model         35427 non-null  object \n",
      " 2   cert_max_gr_wt     35427 non-null  float64\n",
      " 3   acft_category      35427 non-null  object \n",
      " 4   damage             35427 non-null  object \n",
      " 5   far_part           35427 non-null  object \n",
      " 6   afm_hrs_last_insp  35427 non-null  float64\n",
      " 7   type_fly           35427 non-null  object \n",
      " 8   dprt_state         35427 non-null  object \n",
      " 9   rwy_len            35427 non-null  float64\n",
      " 10  rwy_width          35427 non-null  float64\n",
      " 11  ev_type            35427 non-null  object \n",
      " 12  ev_city            35427 non-null  object \n",
      " 13  ev_state           35427 non-null  object \n",
      " 14  ev_country         35427 non-null  object \n",
      " 15  sky_cond_ceil      35427 non-null  object \n",
      " 16  sky_cond_nonceil   35427 non-null  object \n",
      " 17  wx_int_precip      35427 non-null  object \n",
      " 18  phase_flt_spec     35427 non-null  object \n",
      " 19  Injury             35427 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(15)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "injury_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b35149a",
   "metadata": {},
   "source": [
    "Now we will one hot encode `injury_df` so they can be used in our models.\n",
    "\n",
    "1. For classification of `Injury`, the our X and y are called `inj_X` and `inj_y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5921ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_X = injury_df.drop(\"Injury\", axis = 1).copy()\n",
    "inj_y = injury_df[\"Injury\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b051c",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding `inj_X` and `inj_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cf5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode specific columns without standardizing and scaling continuous variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_features_inj = ['acft_make', 'acft_model', 'acft_category', 'damage','far_part', 'type_fly',\n",
    "                        'dprt_state','ev_type','ev_city', 'ev_state','ev_country', 'sky_cond_ceil', 'sky_cond_nonceil',\n",
    "                        'wx_int_precip', 'phase_flt_spec']\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "X_inj_object = inj_X.select_dtypes('object')\n",
    "ohe.fit(X_inj_object)\n",
    "\n",
    "codes_inj = ohe.transform(X_inj_object).toarray()\n",
    "feature_names_inj = ohe.get_feature_names_out(categorical_features_inj)\n",
    "\n",
    "inj_X = pd.concat([inj_X.select_dtypes(exclude='object'), \n",
    "               pd.DataFrame(codes_inj,columns=feature_names_inj).astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352d39a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>rwy_width</th>\n",
       "      <th>acft_make_ LARSON</th>\n",
       "      <th>acft_make_1977 COLFER-CHAN</th>\n",
       "      <th>acft_make_2001 MCGIRL</th>\n",
       "      <th>acft_make_781569 INC</th>\n",
       "      <th>acft_make_A PAIR OF JACKS</th>\n",
       "      <th>acft_make_A. H. GETTINGS</th>\n",
       "      <th>...</th>\n",
       "      <th>phase_flt_spec_GOAROUND</th>\n",
       "      <th>phase_flt_spec_HOVER</th>\n",
       "      <th>phase_flt_spec_LANDING</th>\n",
       "      <th>phase_flt_spec_MANEUVERING</th>\n",
       "      <th>phase_flt_spec_OTHER</th>\n",
       "      <th>phase_flt_spec_STANDING</th>\n",
       "      <th>phase_flt_spec_TAKEOFF</th>\n",
       "      <th>phase_flt_spec_TAXI</th>\n",
       "      <th>phase_flt_spec_UNK</th>\n",
       "      <th>phase_flt_spec_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3800.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cert_max_gr_wt  afm_hrs_last_insp  rwy_len  rwy_width  acft_make_ LARSON  \\\n",
       "0        750000.0              113.0  11800.0      150.0                  0   \n",
       "1          2300.0               40.0   6398.0      150.0                  0   \n",
       "2          3800.0               49.0   2610.0       40.0                  0   \n",
       "3         14100.0                3.0   5500.0      100.0                  0   \n",
       "4          6000.0               13.0   3800.0       36.0                  0   \n",
       "\n",
       "   acft_make_1977 COLFER-CHAN  acft_make_2001 MCGIRL  acft_make_781569 INC  \\\n",
       "0                           0                      0                     0   \n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           0                      0                     0   \n",
       "\n",
       "   acft_make_A PAIR OF JACKS  acft_make_A. H. GETTINGS                  ...  \\\n",
       "0                          0                                         0  ...   \n",
       "1                          0                                         0  ...   \n",
       "2                          0                                         0  ...   \n",
       "3                          0                                         0  ...   \n",
       "4                          0                                         0  ...   \n",
       "\n",
       "   phase_flt_spec_GOAROUND  phase_flt_spec_HOVER  phase_flt_spec_LANDING  \\\n",
       "0                        0                     0                       1   \n",
       "1                        0                     0                       0   \n",
       "2                        0                     0                       0   \n",
       "3                        0                     0                       0   \n",
       "4                        0                     0                       0   \n",
       "\n",
       "   phase_flt_spec_MANEUVERING  phase_flt_spec_OTHER  phase_flt_spec_STANDING  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           0                     0                        0   \n",
       "3                           0                     0                        0   \n",
       "4                           0                     0                        0   \n",
       "\n",
       "   phase_flt_spec_TAKEOFF  phase_flt_spec_TAXI  phase_flt_spec_UNK  \\\n",
       "0                       0                    0                   0   \n",
       "1                       0                    0                   0   \n",
       "2                       0                    0                   0   \n",
       "3                       0                    0                   0   \n",
       "4                       0                    0                   0   \n",
       "\n",
       "   phase_flt_spec_UNKNOWN  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 18468 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde30308",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_X = inj_X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723aad5",
   "metadata": {},
   "source": [
    "#### Label encoding `inj_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0832d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "LE.fit(inj_y)\n",
    "inj_y = LE.transform(inj_y)\n",
    "inj_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262a0b7",
   "metadata": {},
   "source": [
    "### 1b. Data Preparation for predicting the Phase of Flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21d81c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LANDING        16743\n",
       "TAKEOFF         5776\n",
       "APPROACH        3300\n",
       "DESCENT         2995\n",
       "MANEUVERING     1569\n",
       "CRUISE          1218\n",
       "CLIMB            923\n",
       "TAXI             741\n",
       "STANDING         393\n",
       "GOAROUND         301\n",
       "HOVER             94\n",
       "Name: phase_flt_spec, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removed columns that contain UNKNOWN, UNK and OTHER factor levels\n",
    "new_phase_df = phase_df[(phase_df['phase_flt_spec'] != \"UNKNOWN\") & (phase_df['phase_flt_spec'] != \"UNK\") & (phase_df['phase_flt_spec'] != \"OTHER\")].copy()\n",
    "new_phase_df[\"phase_flt_spec\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fddc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phase_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53f2988a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_phase_df[\"phase_flt_spec\"] = new_phase_df[\"phase_flt_spec\"].replace({\"APPROACH\":1,\"CLIMB\":2,\n",
    "                                                                         \"CRUISE\":3,\"DESCENT\":4,\n",
    "                                                                         \"GOAROUND\":5,\"HOVER\":6,\n",
    "                                                                         \"LANDING\":7,\"MANEUVERING\":8,\n",
    "                                                                         \"STANDING\":9,\"TAKEOFF\":10,\n",
    "                                                                         \"TAXI\":11})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7cd2b",
   "metadata": {},
   "source": [
    "#### Preprocessing and Final Dataset description for Multiclass Classification: `phase_flt_spec` \n",
    "\n",
    "\n",
    "The response variable for the second classification problem is called `phase_flt_spec`. This variable is the broad phase of flight where an incident has occurred. So there are three factor levels that were removed called `UNKNOWN`, `UNK` and `OTHER`, because we would like to predict specific broad phases of flights where aviation accidents occured. Additionally, we wanted to include the several injury columns in this dataframe because it may be important in predicting the broad phase. inj_f_grnd, inj_m_grnd, and inj_s_grnd represent the number of minor, fatal and serious ground injuries. Total_Fatal_Injuries, Total_Minor_Injuries, Total_Serious_Injuries correspond to the number of injuries occured that were serious, minor, or fatal on the flight. The Total_Uninjured correspond to the total number of uninjured people on the flight and Total_Injuries_Flight correspond to the total number of injuries that have occured on the flight. So we are left with 26 predictors and 35,427 instances. The response variable has 11 factor levels for each broad phase of flight which have been coded to integers. Shown here:\n",
    "\n",
    "|phase_flt_spec||Code|\n",
    "|----||----|\n",
    "|APPROACH||1|\n",
    "|CLIMB||2|\n",
    "|CRUISE||3|\n",
    "|DESCENT||4|\n",
    "|GOAROUND||5|\n",
    "|HOVER||6|\n",
    "|LANDING||7|\n",
    "|MANEUVERING||8|\n",
    "|STANDING||9|\n",
    "|TAKEOFF||10|\n",
    "|TAXI||11|\n",
    "\n",
    "Our final preprocess method was one-hot encoding our categorical variables. We did not standardize and scale continuous predictors for the same reasons before. Certain aircraft weights (cert_max_gr_wt) and runway widths (rwy_width) may be more prone to causing an incident/accident at a specific phase of flight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e1079",
   "metadata": {},
   "source": [
    "**The final dataframe for classifying `phase_flt_spec` is called `new_phase_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2c9697f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34053 entries, 0 to 34052\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   acft_make               34053 non-null  object \n",
      " 1   acft_model              34053 non-null  object \n",
      " 2   cert_max_gr_wt          34053 non-null  float64\n",
      " 3   acft_category           34053 non-null  object \n",
      " 4   damage                  34053 non-null  object \n",
      " 5   far_part                34053 non-null  object \n",
      " 6   afm_hrs_last_insp       34053 non-null  float64\n",
      " 7   type_fly                34053 non-null  object \n",
      " 8   dprt_state              34053 non-null  object \n",
      " 9   rwy_len                 34053 non-null  float64\n",
      " 10  rwy_width               34053 non-null  float64\n",
      " 11  ev_type                 34053 non-null  object \n",
      " 12  ev_city                 34053 non-null  object \n",
      " 13  ev_state                34053 non-null  object \n",
      " 14  ev_country              34053 non-null  object \n",
      " 15  inj_f_grnd              34053 non-null  float64\n",
      " 16  inj_m_grnd              34053 non-null  float64\n",
      " 17  inj_s_grnd              34053 non-null  float64\n",
      " 18  Total_Fatal_Injuries    34053 non-null  float64\n",
      " 19  Total_Minor_Injuries    34053 non-null  float64\n",
      " 20  Total_Uninjured         34053 non-null  float64\n",
      " 21  Total_Serious_Injuries  34053 non-null  float64\n",
      " 22  Total_Injuries_Flight   34053 non-null  float64\n",
      " 23  sky_cond_ceil           34053 non-null  object \n",
      " 24  sky_cond_nonceil        34053 non-null  object \n",
      " 25  wx_int_precip           34053 non-null  object \n",
      " 26  phase_flt_spec          34053 non-null  int64  \n",
      "dtypes: float64(12), int64(1), object(14)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_phase_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82a891",
   "metadata": {},
   "source": [
    "Now we will one hot encode `new_phase_df` so they can be used in our models.\n",
    "\n",
    "2. For classfication of `phase_flt_spec` (Broad Phase of Flight), the X and y are called `phase_X` and `phase_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73153a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phase_df = new_phase_df.drop('ev_state', axis = 1).copy()\n",
    "new_phase_df = new_phase_df.drop('dprt_state', axis = 1).copy()\n",
    "new_phase_df = new_phase_df.drop('ev_city', axis = 1).copy()\n",
    "phase_X = new_phase_df.drop(\"phase_flt_spec\", axis = 1).copy()\n",
    "\n",
    "\n",
    "phase_y = new_phase_df[\"phase_flt_spec\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39570880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acft_make</th>\n",
       "      <th>acft_model</th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>acft_category</th>\n",
       "      <th>damage</th>\n",
       "      <th>far_part</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>type_fly</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>rwy_width</th>\n",
       "      <th>...</th>\n",
       "      <th>inj_m_grnd</th>\n",
       "      <th>inj_s_grnd</th>\n",
       "      <th>Total_Fatal_Injuries</th>\n",
       "      <th>Total_Minor_Injuries</th>\n",
       "      <th>Total_Uninjured</th>\n",
       "      <th>Total_Serious_Injuries</th>\n",
       "      <th>Total_Injuries_Flight</th>\n",
       "      <th>sky_cond_ceil</th>\n",
       "      <th>sky_cond_nonceil</th>\n",
       "      <th>wx_int_precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>747-100</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>MINR</td>\n",
       "      <td>121</td>\n",
       "      <td>113.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SCAT</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>207</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>135</td>\n",
       "      <td>49.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEECH</td>\n",
       "      <td>300</td>\n",
       "      <td>14100.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>DEST</td>\n",
       "      <td>091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>EXEC</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>MOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AERO COMMANDER</td>\n",
       "      <td>560A</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>DEST</td>\n",
       "      <td>091</td>\n",
       "      <td>13.0</td>\n",
       "      <td>PERS</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>CLER</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GETTIS H. HUDSON</td>\n",
       "      <td>CORBAN BABY ACE</td>\n",
       "      <td>900.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>091</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PERS</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>OVCT</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acft_make            acft_model  cert_max_gr_wt  \\\n",
       "0  BOEING                          747-100                     750000.0   \n",
       "1  CESSNA                          207                           3800.0   \n",
       "2  BEECH                           300                          14100.0   \n",
       "3  AERO COMMANDER                  560A                          6000.0   \n",
       "4  GETTIS H. HUDSON                CORBAN BABY ACE                900.0   \n",
       "\n",
       "  acft_category damage far_part  afm_hrs_last_insp type_fly  rwy_len  \\\n",
       "0          AIR    MINR     121               113.0     UNK   11800.0   \n",
       "1          AIR    SUBS     135                49.0     UNK    2610.0   \n",
       "2          AIR    DEST     091                 3.0     EXEC   5500.0   \n",
       "3          AIR    DEST     091                13.0     PERS   3800.0   \n",
       "4          AIR    SUBS     091                10.0     PERS   1900.0   \n",
       "\n",
       "   rwy_width  ... inj_m_grnd inj_s_grnd  Total_Fatal_Injuries  \\\n",
       "0      150.0  ...        0.0        0.0                   0.0   \n",
       "1       40.0  ...        0.0        0.0                   0.0   \n",
       "2      100.0  ...        0.0        0.0                   2.0   \n",
       "3       36.0  ...        0.0        0.0                   2.0   \n",
       "4       75.0  ...        0.0        0.0                   0.0   \n",
       "\n",
       "   Total_Minor_Injuries  Total_Uninjured  Total_Serious_Injuries  \\\n",
       "0                   0.0              4.0                     0.0   \n",
       "1                   0.0              1.0                     0.0   \n",
       "2                   0.0              0.0                     0.0   \n",
       "3                   0.0              0.0                     2.0   \n",
       "4                   0.0              1.0                     0.0   \n",
       "\n",
       "   Total_Injuries_Flight  sky_cond_ceil  sky_cond_nonceil  wx_int_precip  \n",
       "0                    0.0           NONE              SCAT            UNK  \n",
       "1                    0.0            BKN               UNK            UNK  \n",
       "2                    2.0            BKN               UNK            MOD  \n",
       "3                    4.0           NONE              CLER            UNK  \n",
       "4                    0.0           NONE              OVCT            UNK  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d89495",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding `phase_X` and `phase_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e103644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode specific columns without standardizing and scaling continuous variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_features_phase = ['acft_make', 'acft_model', 'acft_category', 'damage','far_part', 'type_fly',\n",
    "                        'ev_type','ev_country', 'sky_cond_ceil',\n",
    "                        'sky_cond_nonceil','wx_int_precip']\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "X_phase_object = phase_X.select_dtypes('object')\n",
    "ohe.fit(X_phase_object)\n",
    "\n",
    "codes_phase = ohe.transform(X_phase_object).toarray()\n",
    "feature_names_phase = ohe.get_feature_names_out(categorical_features_phase)\n",
    "\n",
    "phase_X = pd.concat([phase_X.select_dtypes(exclude='object'), \n",
    "               pd.DataFrame(codes_phase,columns=feature_names_phase).astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee5aa270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>rwy_width</th>\n",
       "      <th>inj_f_grnd</th>\n",
       "      <th>inj_m_grnd</th>\n",
       "      <th>inj_s_grnd</th>\n",
       "      <th>Total_Fatal_Injuries</th>\n",
       "      <th>Total_Minor_Injuries</th>\n",
       "      <th>Total_Uninjured</th>\n",
       "      <th>...</th>\n",
       "      <th>sky_cond_nonceil_CLER</th>\n",
       "      <th>sky_cond_nonceil_FEW</th>\n",
       "      <th>sky_cond_nonceil_OVCT</th>\n",
       "      <th>sky_cond_nonceil_POBS</th>\n",
       "      <th>sky_cond_nonceil_SCAT</th>\n",
       "      <th>sky_cond_nonceil_UNK</th>\n",
       "      <th>wx_int_precip_LGT</th>\n",
       "      <th>wx_int_precip_LT</th>\n",
       "      <th>wx_int_precip_MOD</th>\n",
       "      <th>wx_int_precip_UNK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8695 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cert_max_gr_wt  afm_hrs_last_insp  rwy_len  rwy_width  inj_f_grnd  \\\n",
       "0        750000.0              113.0  11800.0      150.0         0.0   \n",
       "1          3800.0               49.0   2610.0       40.0         0.0   \n",
       "2         14100.0                3.0   5500.0      100.0         0.0   \n",
       "3          6000.0               13.0   3800.0       36.0         0.0   \n",
       "4           900.0               10.0   1900.0       75.0         0.0   \n",
       "\n",
       "   inj_m_grnd  inj_s_grnd  Total_Fatal_Injuries  Total_Minor_Injuries  \\\n",
       "0         0.0         0.0                   0.0                   0.0   \n",
       "1         0.0         0.0                   0.0                   0.0   \n",
       "2         0.0         0.0                   2.0                   0.0   \n",
       "3         0.0         0.0                   2.0                   0.0   \n",
       "4         0.0         0.0                   0.0                   0.0   \n",
       "\n",
       "   Total_Uninjured  ...  sky_cond_nonceil_CLER  sky_cond_nonceil_FEW  \\\n",
       "0              4.0  ...                      0                     0   \n",
       "1              1.0  ...                      0                     0   \n",
       "2              0.0  ...                      0                     0   \n",
       "3              0.0  ...                      1                     0   \n",
       "4              1.0  ...                      0                     0   \n",
       "\n",
       "   sky_cond_nonceil_OVCT  sky_cond_nonceil_POBS  sky_cond_nonceil_SCAT  \\\n",
       "0                      0                      0                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      1                      0                      0   \n",
       "\n",
       "   sky_cond_nonceil_UNK  wx_int_precip_LGT  wx_int_precip_LT  \\\n",
       "0                     0                  0                 0   \n",
       "1                     1                  0                 0   \n",
       "2                     1                  0                 0   \n",
       "3                     0                  0                 0   \n",
       "4                     0                  0                 0   \n",
       "\n",
       "   wx_int_precip_MOD  wx_int_precip_UNK  \n",
       "0                  0                  1  \n",
       "1                  0                  1  \n",
       "2                  1                  0  \n",
       "3                  0                  1  \n",
       "4                  0                  1  \n",
       "\n",
       "[5 rows x 8695 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ea0c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_X = phase_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "293d133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 0, ..., 4, 6, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "LE.fit(phase_y)\n",
    "phase_y = LE.transform(phase_y)\n",
    "phase_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e103bcae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.500e+05, 1.130e+02, 1.180e+04, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.800e+03, 4.900e+01, 2.610e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [1.410e+04, 3.000e+00, 5.500e+03, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.320e+03, 1.000e+00, 6.000e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [1.450e+03, 4.400e+01, 4.000e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.190e+03, 6.500e+01, 6.143e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b648c9",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f911e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "cv_log = StratifiedShuffleSplit(n_splits=5,test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57784456",
   "metadata": {},
   "source": [
    "#### Logistic Regression for predicting `Injury`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ebb4bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy: 0.8281117696867062\n",
      "CPU times: user 34.2 s, sys: 5.46 s, total: 39.7 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "import time\n",
    "lr_clf = LogisticRegression(solver='liblinear', penalty=\"l2\",max_iter=1000,random_state=42)\n",
    "iter_num=0\n",
    "for train_indices, test_indices in cv.split(inj_X,inj_y): \n",
    "#     start = time.time()\n",
    "#     elapsed_time = (time.time() - start)\n",
    "    X_train = inj_X[train_indices]\n",
    "    y_train = inj_y[train_indices]\n",
    "    \n",
    "    X_test = inj_X[test_indices]\n",
    "    y_test = inj_y[test_indices]\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "#     print(conf )\n",
    "#     print('CV Time: ', elapsed_time)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29f426",
   "metadata": {},
   "source": [
    "Grid Search for Injury: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f093f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1143, in _fit_liblinear\n",
      "    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\n",
      "  File \"/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 58, in compute_class_weight\n",
      "    raise ValueError(\n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'none'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.78509738        nan 0.8001129         nan 0.8165961         nan\n",
      " 0.80180638        nan 0.81055603        nan 0.8084674         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 9.37 s, total: 29.4 s\n",
      "Wall time: 16min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "             estimator=LogisticRegression(), n_jobs=8,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'class_weight': ['balanced', 'none'],\n",
       "                         'max_iter': [1000], 'penalty': ['l2'],\n",
       "                         'random_state': [42], 'solver': ['liblinear']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "              ,'class_weight': ['balanced','none']\n",
    "              ,'random_state': [42]\n",
    "              ,'solver': ['liblinear']\n",
    "              ,'max_iter':[1000]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "inj_GridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_log # KFolds = 5\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "inj_GridSearch.fit(inj_X, inj_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4197979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5204f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 1000,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_GridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870f14c",
   "metadata": {},
   "source": [
    "#### Logistic Regression for predicting `phase_flt_spec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa983793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy: 0.5164415736934821\n",
      "[[  36    0    2    1    1    0  268    2    0   20    0]\n",
      " [   5    1    0    1    0    0   81    0    0    4    0]\n",
      " [   2    0    1   11    0    0   89   13    0    6    0]\n",
      " [  18    0    0   22    0    1  216   24    0   19    0]\n",
      " [   1    0    0    0    0    0   28    0    0    1    0]\n",
      " [   0    0    0    1    0    0    8    0    0    0    0]\n",
      " [   1    2    0    7    0    0 1647    5    0   13    0]\n",
      " [   4    0    0   10    0    0  114   17    0   12    0]\n",
      " [   2    0    0    0    0    0   35    0    0    2    0]\n",
      " [   8    0    1    4    0    0  529    2    0   34    0]\n",
      " [   0    0    0    0    0    0   72    0    0    1    1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "import time\n",
    "lr_phase = LogisticRegression(solver='liblinear', penalty=\"l2\",max_iter=1000,random_state=42)\n",
    "# scl_obj = StandardScaler()\n",
    "# scl_obj.fit(X_train)\n",
    "iter_num=0\n",
    "for train_indices, test_indices in cv.split(phase_X,phase_y): \n",
    "    X_train = phase_X[train_indices]\n",
    "    y_train = phase_y[train_indices]\n",
    "    \n",
    "    X_test = phase_X[test_indices]\n",
    "    y_test = phase_y[test_indices]\n",
    "#     scl_obj.fit(X_train)\n",
    "#     X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "#     X_test_scaled = scl_obj.transform(X_test)\n",
    "    lr_phase.fit(X_train,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_phase.predict(X_test) # get test set predictions\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "              ,'class_weight': ['balanced','none']\n",
    "              ,'random_state': [42]\n",
    "              ,'solver': ['liblinear']\n",
    "              ,'max_iter':[1000]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "phase_GridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_log # KFolds = 5\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "phase_GridSearch.fit(inj_X, inj_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_GridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86313ec4",
   "metadata": {},
   "source": [
    "### KNN classifier\n",
    "The KNN algorithm assumes that similar things exist in proximity. It can be used as a classifier to implement the k-nearest neighbors. KNN is used to make predictions. For our dataset, we will be using KNN to predict injury. Our datatest was scaled since KNN classifier requires that. We will be using stratified k-fold cross-validation because with this the mean response value is approximately equal in all the folds. Each test fold has equal class labels. For the KNN classifier, our evaluation metrics will be the accuracy, precision, AUC.\n",
    "\n",
    "#### Accuracy\n",
    "This will be used to predict which model performs better at prediction. This will be an important metric in predicting an injury. \n",
    "$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "#### Precision\n",
    "Precision is the ratio between the True Positives and all the Positives. For our classification, it would be a measure of accidents that could lead to an injury.\n",
    "$Precision = \\frac{TP}{PP}$\n",
    "\n",
    "#### Area under the Curve\n",
    "AUC will measure the performance of our classification problem at different thresholds. The AUC model will be used to evaluate which model is accurate. The closer the model to 1, the more it is a good model to distinguish between negative and positive scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "addbea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def InjuryEvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, inj_X, inj_y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbc4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def PhaseEvaluateClassifierEstimator(classifierEstimator, phase_X, phase_y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, phase_X, phase_y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "860df217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy 0.4836706466819093\n",
      "KNN precision 0.6158906882591093\n",
      "KNN confusion_matrix [[15918   759]\n",
      " [17533  1217]]\n",
      "CPU times: user 2min 31s, sys: 5.99 s, total: 2min 37s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat = np.zeros(inj_y.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "#cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "for train, test in cv.split(inj_X,inj_y):\n",
    "    clf.fit(inj_X[train],inj_y[train])\n",
    "    yhat[test] = clf.predict(inj_X[test])\n",
    "\n",
    "total_accuracy = mt.accuracy_score(inj_y, yhat)\n",
    "print ('KNN accuracy', total_accuracy)\n",
    "total_precision = mt.precision_score(inj_y, yhat)\n",
    "print ('KNN precision', total_precision)\n",
    "total_confusion_matrix = mt.confusion_matrix(inj_y, yhat)\n",
    "print ('KNN confusion_matrix', total_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b059d36f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.39 GiB for an array with shape (31884, 18468) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-214e68c8de79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mInjuryEvaluateClassifierEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minj_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minj_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-e7cb7486f82f>\u001b[0m in \u001b[0;36mInjuryEvaluateClassifierEstimator\u001b[1;34m(classifierEstimator, X, y, cv)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#Perform cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     scores = cross_validate(classifierEstimator, inj_X, inj_y, scoring=['accuracy','precision','recall']\n\u001b[0m\u001b[0;32m      7\u001b[0m                             , cv=cv, return_train_score=True)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[1;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mX_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.39 GiB for an array with shape (31884, 18468) and data type float64"
     ]
    }
   ],
   "source": [
    "InjuryEvaluateClassifierEstimator(clf, inj_X, inj_y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4a68b",
   "metadata": {},
   "source": [
    "We had an accuracy of about 71.6%. We will try k=5 to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d72be654",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat = np.zeros(y.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "for train, test in cv.split(X,y):\n",
    "    clf.fit(X[train],y[train])\n",
    "    yhat[test] = clf.predict(X[test])\n",
    "\n",
    "total_accuracy = mt.accuracy_score(y, yhat)\n",
    "print ('KNN accuracy', total_accuracy)\n",
    "total_precision = mt.precision_score(y, yhat)\n",
    "print ('KNN precision', total_precision)\n",
    "total_confusion_matrix = mt.confusion_matrix(y, yhat)\n",
    "print ('KNN confusion_matrix', total_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "We had an accuracy of 72% for k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(total_confusion_matrix, annot=True, fmt = \"d\", cmap=\"Spectral\"); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('ACTUAL LABELS');ax.set_ylabel('PREDICTED LABELS'); \n",
    "ax.set_title('KNN Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['11', '12','13','21','22','23','31','32','33']); ax.yaxis.set_ticklabels(['Soft', 'Tough']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85715943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accuracy(ytrue,yhat):\n",
    "    conf = mt.confusion_matrix(ytrue,yhat)\n",
    "    norm_conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    return np.diag(norm_conf)\n",
    "\n",
    "def plot_class_acc(ytrue,yhat, title=''):\n",
    "    acc_list = per_class_accuracy(ytrue,yhat)\n",
    "    plt.bar(range(len(acc_list)), acc_list)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.title(title+\", Total Acc=%.1f\"%(100*mt.accuracy_score(ytrue,yhat)))\n",
    "    plt.grid()\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_class_acc(y,yhat,title=\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a7286",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "We will plot the ROC curve which is a plot of True Positive Rate vs False Positive Rate. The AUC-ROC will help us visualize how well our KNN classifier is performing. For our dataset, We save the outputs into a dictionary of fpr and tpr (false positive and true positive rates). The keys to the dictionary are the class value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_scores = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27790e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform hyperparameter search to find the best k value\n",
    "param_grid = {'n_neighbors':np.arange(1,21)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=10)\n",
    "knn_cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will try the roc curve with new k value\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors = 20)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_scores = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27671ebe",
   "metadata": {},
   "source": [
    "We had a better AUC score of 86% with k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58224f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
