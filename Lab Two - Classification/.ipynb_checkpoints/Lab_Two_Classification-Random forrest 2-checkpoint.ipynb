{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31dded7",
   "metadata": {},
   "source": [
    "You are to build upon the predictive analysis (classification) that you already completed in the previous mini-project, adding additional modeling from new classification algorithms as well as more explanations that are inline with the CRISP-DM framework. You should use appropriate cross validation for all of your analysis (explain your chosen method of performance validation in detail). Try to use as much testing data as possible in a realistic manner (you should define what you think is realistic and why).\n",
    "This report is worth 20% of the final grade. Please upload a report (one per team) with all code used, visualizations, and text in a single document. The format of the document can be PDF, *.ipynb, or HTML. You can write the report in whatever format you like, but it is easiest to turn in the rendered iPython notebook. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report.\n",
    "\n",
    "### Dataset Selection\n",
    "Select a dataset identically to the way you selected for the first project work week and mini-project. You are not required to use the same dataset that you used in the past, but you are encouraged. You must identify two tasks from the dataset to regress or classify. That is:\n",
    "- two classification tasks OR\n",
    "- two regression tasks OR\n",
    "- one classification task and one regression task\n",
    "\n",
    "For example, if your dataset was from the diabetes data you might try to predict two tasks: (1) classifying if a patient will be readmitted within a 30 day period or not, and (2) regressing what the total number of days a patient will spend in the hospital, given their history and specifics of the encounter like tests administered and previous admittance.\n",
    "\n",
    "### Grading Rubric\n",
    "\n",
    "#### Data Preparation (15 points total)\n",
    "- [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "\n",
    "### Modeling and Evaluation (70 points total)\n",
    "\n",
    "- [10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [10 points] Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate.\n",
    "\n",
    "**Satvik** - write detailed explanation\n",
    "\n",
    "- [20 points] Create three different classification/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric.\n",
    "\n",
    "Logistic Regression FOR Injury and Phase - Satvik\n",
    "With grid search for both Injury and Phase - Satvik\n",
    "\n",
    "KNN FOR Injury and Phase - Nnenna\n",
    "With grid search for both Injury and Phase - Nnenna\n",
    "[Thursday]\n",
    "\n",
    "Random Forest FOR Injury and Phase - Jobin\n",
    "With grid search for both Injury and Phase - Jobin\n",
    "[Thursday]\n",
    "get feature importance - Jobin\n",
    "\n",
    "\n",
    "- [10 points] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "Dylan - Create table for 3 Injury grid search models and 3 Phase of flight grid search models \n",
    "-make more colorful confusion matrix\n",
    "[Thursday]\n",
    "\n",
    "- [10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods.\n",
    "\n",
    "Dylan - model advantages\n",
    "use package that Jake told us to use for statistical comparison -  Dylan\n",
    "\n",
    "- [10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "Random Forest has feature importance maybe use this\n",
    "\n",
    "### Deployment (5 points total)\n",
    "\n",
    "- [5 points] How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "Dylan\n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "\n",
    "YAY done kind of...\n",
    "\n",
    "- You have free reign to provide additional modeling.\n",
    "- One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150ed1d",
   "metadata": {},
   "source": [
    "Two dataframes for each classification task\n",
    "\n",
    "Data cleanup (Dylan and Satvik)\n",
    "Broad phase of flight dataframe\n",
    "\n",
    "Injury (Injury)  for KNN (Nnenna)\n",
    "- Look into ROC Curves\n",
    "- Look at Sklearn parameters for KNN\n",
    "\n",
    "\n",
    "Injury (Injury) for Decision Trees (Jobin)\n",
    "- Look at Sklearn parameters for decision trees\n",
    "\n",
    "Injury (Injury) for KNN\n",
    "\n",
    "Injury (Injury) for Decision Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95494b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628c91b",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f390e0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115706 entries, 0 to 115705\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   acft_make          115643 non-null  object \n",
      " 1   acft_model         115630 non-null  object \n",
      " 2   cert_max_gr_wt     98673 non-null   float64\n",
      " 3   acft_category      115287 non-null  object \n",
      " 4   damage             113877 non-null  object \n",
      " 5   far_part           114925 non-null  object \n",
      " 6   afm_hrs_last_insp  60298 non-null   float64\n",
      " 7   type_fly           108599 non-null  object \n",
      " 8   dprt_state         108791 non-null  object \n",
      " 9   rwy_len            64222 non-null   float64\n",
      " 10  rwy_width          63110 non-null   float64\n",
      " 11  ev_type            115706 non-null  object \n",
      " 12  ev_city            115646 non-null  object \n",
      " 13  ev_state           109635 non-null  object \n",
      " 14  ev_country         115199 non-null  object \n",
      " 15  inj_f_grnd         51624 non-null   float64\n",
      " 16  inj_m_grnd         51543 non-null   float64\n",
      " 17  inj_s_grnd         51520 non-null   float64\n",
      " 18  inj_tot_f          64375 non-null   float64\n",
      " 19  inj_tot_m          63902 non-null   float64\n",
      " 20  inj_tot_n          90784 non-null   float64\n",
      " 21  inj_tot_s          60713 non-null   float64\n",
      " 22  inj_tot_t          79933 non-null   float64\n",
      " 23  sky_cond_ceil      104219 non-null  object \n",
      " 24  sky_cond_nonceil   100624 non-null  object \n",
      " 25  wx_int_precip      49898 non-null   object \n",
      " 26  phase_flt_spec     113882 non-null  object \n",
      "dtypes: float64(12), object(15)\n",
      "memory usage: 23.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read in the Aviation Data\n",
    "final_data = pd.read_csv(\"../Data/final_data.csv\",low_memory=False,dtype={'damage': str})\n",
    "#Delete columns that were imported incorrectly\n",
    "del final_data[\"Unnamed: 0\"]\n",
    "del final_data[\"dprt_state.1\"]\n",
    "del final_data[\"dprt_city\"]\n",
    "del final_data[\"index\"]\n",
    "del final_data[\"ntsb_no_x\"]\n",
    "del final_data['wind_vel_ind']\n",
    "del final_data[\"ev_id\"]\n",
    "del final_data['ev_highest_injury']\n",
    "\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abe9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the all empty values to Nan\n",
    "final_data= final_data.replace(r'^\\s+$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b817bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper case all factor levels for each categorical variable\n",
    "final_data['acft_make'] = final_data['acft_make'].str.upper()\n",
    "final_data['acft_category'] = final_data['acft_category'].str.upper()\n",
    "final_data['damage'] = final_data['damage'].str.upper()\n",
    "final_data['type_fly'] = final_data['type_fly'].str.upper()\n",
    "final_data['dprt_state'] = final_data['dprt_state'].str.upper()\n",
    "final_data['ev_city'] = final_data['ev_city'].str.upper()\n",
    "final_data['ev_type'] = final_data['ev_type'].str.upper()\n",
    "final_data['ev_city'] = final_data['ev_city'].str.upper()\n",
    "final_data['ev_country'] = final_data['ev_country'].str.upper()\n",
    "final_data['sky_cond_ceil'] = final_data['sky_cond_ceil'].str.upper()\n",
    "final_data['sky_cond_nonceil'] = final_data['sky_cond_nonceil'].str.upper()\n",
    "final_data['wx_int_precip'] = final_data['wx_int_precip'].str.upper()\n",
    "final_data['phase_flt_spec'] = final_data['phase_flt_spec'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "507e517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.loc[final_data['damage'].str.contains('UNK', na=False), 'damage'] = 'UNK'\n",
    "\n",
    "#rename the injuries columns to make them easier to read\n",
    "final_data = final_data.rename(columns={\"inj_tot_f\": \"Total_Fatal_Injuries\", \n",
    "                                        \"inj_tot_s\":\"Total_Serious_Injuries\",\n",
    "                                        \"inj_tot_m\":\"Total_Minor_Injuries\",\n",
    "                                        \"inj_tot_n\":'Total_Uninjured',\n",
    "                                        \"inj_tot_t\":\"Total_Injuries_Flight\"})\n",
    "\n",
    "#fill in 0s when there wasn't an injury in that category\n",
    "final_data.update(final_data[['Total_Fatal_Injuries','Total_Serious_Injuries',\n",
    "                              'Total_Minor_Injuries','Total_Uninjured',\n",
    "                              'Total_Injuries_Flight','inj_f_grnd',\n",
    "                              'inj_m_grnd','inj_s_grnd']].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19dcc9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acft_make</th>\n",
       "      <th>acft_model</th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>acft_category</th>\n",
       "      <th>damage</th>\n",
       "      <th>far_part</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>type_fly</th>\n",
       "      <th>dprt_state</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>...</th>\n",
       "      <th>inj_s_grnd</th>\n",
       "      <th>Total_Fatal_Injuries</th>\n",
       "      <th>Total_Minor_Injuries</th>\n",
       "      <th>Total_Uninjured</th>\n",
       "      <th>Total_Serious_Injuries</th>\n",
       "      <th>Total_Injuries_Flight</th>\n",
       "      <th>sky_cond_ceil</th>\n",
       "      <th>sky_cond_nonceil</th>\n",
       "      <th>wx_int_precip</th>\n",
       "      <th>phase_flt_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>747-100</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>MINR</td>\n",
       "      <td>121</td>\n",
       "      <td>113.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>JA</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SCAT</td>\n",
       "      <td>UNK</td>\n",
       "      <td>LANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>172</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>091</td>\n",
       "      <td>40.0</td>\n",
       "      <td>PERS</td>\n",
       "      <td>UNK</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>LGT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CESSNA</td>\n",
       "      <td>207</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>SUBS</td>\n",
       "      <td>135</td>\n",
       "      <td>49.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AK</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>DESCENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acft_make            acft_model  cert_max_gr_wt  \\\n",
       "0  BOEING                          747-100                     750000.0   \n",
       "1  CESSNA                          172                           2300.0   \n",
       "2  CESSNA                          207                           3800.0   \n",
       "\n",
       "  acft_category damage far_part  afm_hrs_last_insp type_fly dprt_state  \\\n",
       "0          AIR    MINR     121               113.0     UNK          JA   \n",
       "1          AIR    SUBS     091                40.0     PERS        UNK   \n",
       "2          AIR    SUBS     135                49.0     UNK          AK   \n",
       "\n",
       "   rwy_len  ...  inj_s_grnd Total_Fatal_Injuries Total_Minor_Injuries  \\\n",
       "0  11800.0  ...         0.0                  0.0                  0.0   \n",
       "1   6398.0  ...         0.0                  0.0                  0.0   \n",
       "2   2610.0  ...         0.0                  0.0                  0.0   \n",
       "\n",
       "  Total_Uninjured Total_Serious_Injuries  Total_Injuries_Flight  \\\n",
       "0             4.0                    0.0                    0.0   \n",
       "1             1.0                    0.0                    0.0   \n",
       "2             1.0                    0.0                    0.0   \n",
       "\n",
       "   sky_cond_ceil  sky_cond_nonceil  wx_int_precip  phase_flt_spec  \n",
       "0           NONE              SCAT            UNK         LANDING  \n",
       "1            BKN               UNK            LGT         UNKNOWN  \n",
       "2            BKN               UNK            UNK         DESCENT  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.dropna(subset=['cert_max_gr_wt','afm_hrs_last_insp',\n",
    "                          'rwy_len','rwy_width'],inplace=True)\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "final_data.update(final_data.fillna(\"UNK\"))\n",
    "final_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570850b",
   "metadata": {},
   "source": [
    "Created a copy of this dataframe for classifying broad phase of flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5775db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = final_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3952dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Injury\n",
       "0      1   18750\n",
       "1      0   16677"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to account for ALL injuries. This includes injuries on the ground as well as passangers\n",
    "#Here we will make a new column that shows total injuries including ground ones\n",
    "final_data['Total_Injuries_Ground'] = final_data['inj_f_grnd']+final_data['inj_m_grnd']+final_data['inj_s_grnd']\n",
    "final_data['Total_Injuries'] = final_data['Total_Injuries_Ground']+final_data['Total_Injuries_Flight']\n",
    "final_data['Injury'] = np.where(final_data['Total_Injuries'] >0,1,0)\n",
    "injuries = final_data[\"Injury\"].value_counts().reset_index()\n",
    "injuries.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd85106",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_data.copy()\n",
    "#Since we added up all of our injuries we don't need the other columns that include injury count since it will be colinear to our prediction variable\n",
    "final_df = final_df.drop(['Total_Fatal_Injuries','Total_Serious_Injuries','Total_Minor_Injuries',\n",
    "                          'Total_Uninjured','Total_Injuries_Flight','inj_f_grnd','inj_m_grnd',\n",
    "                          'inj_s_grnd','Total_Injuries_Ground',\"Total_Injuries\"],axis = 1)\n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782a03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7462a067",
   "metadata": {},
   "source": [
    "#### Clean up for broad phase of flight dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82ae07",
   "metadata": {},
   "source": [
    "The response variable for the second classification problem is called `phase_flt_spec`. This variable is the broad phase of flight where an incident has occurred. So there are three factor levels that were removed called `UNKNOWN`, `UNK` and `OTHER`, because we would like to predict specific broad phases of flights where aviation accidents occured. Additionally, we wanted to include the several injury columns in this dataframe because it may be important in predicting the broad phase. inj_f_grnd, inj_m_grnd, and inj_s_grnd represent the number of minor, fatal and serious ground injuries. Total_Fatal_Injuries, Total_Minor_Injuries, Total_Serious_Injuries correspond to the number of injuries occured that were serious, minor, or fatal on the flight. The Total_Uninjured correspond to the total number of uninjured people on the flight and Total_Injuries_Flight correspond to the total number of injuries that have occured on the flight. So we are left with 26 predictors and 35,427 instances. The response variable has 11 factor levels for each broad phase of flight which have been coded to integers. This dataframe is called `new_phase_df`. Shown here:\n",
    "\n",
    "|phase_flt_spec||Code|\n",
    "|----||----|\n",
    "|APPROACH||1|\n",
    "|CLIMB||2|\n",
    "|CRUISE||3|\n",
    "|DESCENT||4|\n",
    "|GOAROUND||5|\n",
    "|HOVER||6|\n",
    "|LANDING||7|\n",
    "|MANEUVERING||8|\n",
    "|STANDING||9|\n",
    "|TAKEOFF||10|\n",
    "|TAXI||11|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af71cb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LANDING        16743\n",
       "TAKEOFF         5776\n",
       "APPROACH        3300\n",
       "DESCENT         2995\n",
       "MANEUVERING     1569\n",
       "CRUISE          1218\n",
       "CLIMB            923\n",
       "TAXI             741\n",
       "STANDING         393\n",
       "GOAROUND         301\n",
       "HOVER             94\n",
       "Name: phase_flt_spec, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removed columns that contain UNKNOWN, UNK and OTHER factor levels\n",
    "new_phase_df = phase_df[(phase_df['phase_flt_spec'] != \"UNKNOWN\") & (phase_df['phase_flt_spec'] != \"UNK\") & (phase_df['phase_flt_spec'] != \"OTHER\")].copy()\n",
    "new_phase_df[\"phase_flt_spec\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d78b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phase_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93451a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_phase_df[\"phase_flt_spec\"] = new_phase_df[\"phase_flt_spec\"].replace({\"APPROACH\":1,\"CLIMB\":2,\n",
    "                                                                         \"CRUISE\":3,\"DESCENT\":4,\n",
    "                                                                         \"GOAROUND\":5,\"HOVER\":6,\n",
    "                                                                         \"LANDING\":7,\"MANEUVERING\":8,\n",
    "                                                                         \"STANDING\":9,\"TAKEOFF\":10,\n",
    "                                                                         \"TAXI\":11})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c76570",
   "metadata": {},
   "source": [
    "1. Our final dataframe for classifying `Injury` is called `injury_df`\n",
    "2. Our final dataframe for classifying `phase_flt_spec` is called `new_phase_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c37cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35427 entries, 0 to 35426\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   acft_make          35427 non-null  object \n",
      " 1   acft_model         35427 non-null  object \n",
      " 2   cert_max_gr_wt     35427 non-null  float64\n",
      " 3   acft_category      35427 non-null  object \n",
      " 4   damage             35427 non-null  object \n",
      " 5   far_part           35427 non-null  object \n",
      " 6   afm_hrs_last_insp  35427 non-null  float64\n",
      " 7   type_fly           35427 non-null  object \n",
      " 8   dprt_state         35427 non-null  object \n",
      " 9   rwy_len            35427 non-null  float64\n",
      " 10  rwy_width          35427 non-null  float64\n",
      " 11  ev_type            35427 non-null  object \n",
      " 12  ev_city            35427 non-null  object \n",
      " 13  ev_state           35427 non-null  object \n",
      " 14  ev_country         35427 non-null  object \n",
      " 15  sky_cond_ceil      35427 non-null  object \n",
      " 16  sky_cond_nonceil   35427 non-null  object \n",
      " 17  wx_int_precip      35427 non-null  object \n",
      " 18  phase_flt_spec     35427 non-null  object \n",
      " 19  Injury             35427 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(15)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "injury_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b36f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34053 entries, 0 to 34052\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   acft_make               34053 non-null  object \n",
      " 1   acft_model              34053 non-null  object \n",
      " 2   cert_max_gr_wt          34053 non-null  float64\n",
      " 3   acft_category           34053 non-null  object \n",
      " 4   damage                  34053 non-null  object \n",
      " 5   far_part                34053 non-null  object \n",
      " 6   afm_hrs_last_insp       34053 non-null  float64\n",
      " 7   type_fly                34053 non-null  object \n",
      " 8   dprt_state              34053 non-null  object \n",
      " 9   rwy_len                 34053 non-null  float64\n",
      " 10  rwy_width               34053 non-null  float64\n",
      " 11  ev_type                 34053 non-null  object \n",
      " 12  ev_city                 34053 non-null  object \n",
      " 13  ev_state                34053 non-null  object \n",
      " 14  ev_country              34053 non-null  object \n",
      " 15  inj_f_grnd              34053 non-null  float64\n",
      " 16  inj_m_grnd              34053 non-null  float64\n",
      " 17  inj_s_grnd              34053 non-null  float64\n",
      " 18  Total_Fatal_Injuries    34053 non-null  float64\n",
      " 19  Total_Minor_Injuries    34053 non-null  float64\n",
      " 20  Total_Uninjured         34053 non-null  float64\n",
      " 21  Total_Serious_Injuries  34053 non-null  float64\n",
      " 22  Total_Injuries_Flight   34053 non-null  float64\n",
      " 23  sky_cond_ceil           34053 non-null  object \n",
      " 24  sky_cond_nonceil        34053 non-null  object \n",
      " 25  wx_int_precip           34053 non-null  object \n",
      " 26  phase_flt_spec          34053 non-null  int64  \n",
      "dtypes: float64(12), int64(1), object(14)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_phase_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7263e",
   "metadata": {},
   "source": [
    "Now we will one hot encode both dataframes so they can be used in our models.\n",
    "\n",
    "1. For classification of `Injury`, the our X and y are called `inj_X` and `inj_y`. \n",
    "\n",
    "2. For classfication of `phase_flt_spec` (Broad Phase of Flight), the X and y are called `phase_X` and `phase_y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "925d7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_X = injury_df.drop(\"Injury\", axis = 1).copy()\n",
    "inj_y = injury_df[\"Injury\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76712490",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_X = new_phase_df.drop(\"phase_flt_spec\", axis = 1).copy()\n",
    "phase_y = new_phase_df[\"phase_flt_spec\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cad88a",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding `inj_X` and `inj_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e60a5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode specific columns without standardizing and scaling continuous variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_features_inj = ['acft_make', 'acft_model', 'acft_category', 'damage','far_part', 'type_fly',\n",
    "                        'dprt_state','ev_type','ev_city', 'ev_state','ev_country', 'sky_cond_ceil', 'sky_cond_nonceil',\n",
    "                        'wx_int_precip', 'phase_flt_spec']\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "X_inj_object = inj_X.select_dtypes('object')\n",
    "ohe.fit(X_inj_object)\n",
    "\n",
    "codes_inj = ohe.transform(X_inj_object).toarray()\n",
    "feature_names_inj = ohe.get_feature_names(categorical_features_inj)\n",
    "\n",
    "inj_X = pd.concat([inj_X.select_dtypes(exclude='object'), \n",
    "               pd.DataFrame(codes_inj,columns=feature_names_inj).astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab6081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>rwy_width</th>\n",
       "      <th>acft_make_ LARSON</th>\n",
       "      <th>acft_make_1977 COLFER-CHAN</th>\n",
       "      <th>acft_make_2001 MCGIRL</th>\n",
       "      <th>acft_make_781569 INC</th>\n",
       "      <th>acft_make_A PAIR OF JACKS</th>\n",
       "      <th>acft_make_A. H. GETTINGS</th>\n",
       "      <th>...</th>\n",
       "      <th>phase_flt_spec_GOAROUND</th>\n",
       "      <th>phase_flt_spec_HOVER</th>\n",
       "      <th>phase_flt_spec_LANDING</th>\n",
       "      <th>phase_flt_spec_MANEUVERING</th>\n",
       "      <th>phase_flt_spec_OTHER</th>\n",
       "      <th>phase_flt_spec_STANDING</th>\n",
       "      <th>phase_flt_spec_TAKEOFF</th>\n",
       "      <th>phase_flt_spec_TAXI</th>\n",
       "      <th>phase_flt_spec_UNK</th>\n",
       "      <th>phase_flt_spec_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6398.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3800.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cert_max_gr_wt  afm_hrs_last_insp  rwy_len  rwy_width  acft_make_ LARSON  \\\n",
       "0        750000.0              113.0  11800.0      150.0                  0   \n",
       "1          2300.0               40.0   6398.0      150.0                  0   \n",
       "2          3800.0               49.0   2610.0       40.0                  0   \n",
       "3         14100.0                3.0   5500.0      100.0                  0   \n",
       "4          6000.0               13.0   3800.0       36.0                  0   \n",
       "\n",
       "   acft_make_1977 COLFER-CHAN  acft_make_2001 MCGIRL  acft_make_781569 INC  \\\n",
       "0                           0                      0                     0   \n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           0                      0                     0   \n",
       "\n",
       "   acft_make_A PAIR OF JACKS  acft_make_A. H. GETTINGS                  ...  \\\n",
       "0                          0                                         0  ...   \n",
       "1                          0                                         0  ...   \n",
       "2                          0                                         0  ...   \n",
       "3                          0                                         0  ...   \n",
       "4                          0                                         0  ...   \n",
       "\n",
       "   phase_flt_spec_GOAROUND  phase_flt_spec_HOVER  phase_flt_spec_LANDING  \\\n",
       "0                        0                     0                       1   \n",
       "1                        0                     0                       0   \n",
       "2                        0                     0                       0   \n",
       "3                        0                     0                       0   \n",
       "4                        0                     0                       0   \n",
       "\n",
       "   phase_flt_spec_MANEUVERING  phase_flt_spec_OTHER  phase_flt_spec_STANDING  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           0                     0                        0   \n",
       "3                           0                     0                        0   \n",
       "4                           0                     0                        0   \n",
       "\n",
       "   phase_flt_spec_TAKEOFF  phase_flt_spec_TAXI  phase_flt_spec_UNK  \\\n",
       "0                       0                    0                   0   \n",
       "1                       0                    0                   0   \n",
       "2                       0                    0                   0   \n",
       "3                       0                    0                   0   \n",
       "4                       0                    0                   0   \n",
       "\n",
       "   phase_flt_spec_UNKNOWN  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 18468 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ec7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_X = inj_X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec42f8",
   "metadata": {},
   "source": [
    "#### Label encoding `inj_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c14da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "LE.fit(inj_y)\n",
    "inj_y = LE.transform(inj_y)\n",
    "inj_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62fdae",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding `phase_X` and `phase_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4cd10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode specific columns without standardizing and scaling continuous variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_features_phase = ['acft_make', 'acft_model', 'acft_category', 'damage','far_part', 'type_fly',\n",
    "                        'dprt_state','ev_type','ev_city', 'ev_state','ev_country', 'sky_cond_ceil',\n",
    "                        'sky_cond_nonceil','wx_int_precip']\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "X_phase_object = phase_X.select_dtypes('object')\n",
    "ohe.fit(X_phase_object)\n",
    "\n",
    "codes_phase = ohe.transform(X_phase_object).toarray()\n",
    "feature_names_phase = ohe.get_feature_names(categorical_features_phase)\n",
    "\n",
    "phase_X = pd.concat([phase_X.select_dtypes(exclude='object'), \n",
    "               pd.DataFrame(codes_phase,columns=feature_names_phase).astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9131db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cert_max_gr_wt</th>\n",
       "      <th>afm_hrs_last_insp</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>rwy_width</th>\n",
       "      <th>inj_f_grnd</th>\n",
       "      <th>inj_m_grnd</th>\n",
       "      <th>inj_s_grnd</th>\n",
       "      <th>Total_Fatal_Injuries</th>\n",
       "      <th>Total_Minor_Injuries</th>\n",
       "      <th>Total_Uninjured</th>\n",
       "      <th>...</th>\n",
       "      <th>sky_cond_nonceil_CLER</th>\n",
       "      <th>sky_cond_nonceil_FEW</th>\n",
       "      <th>sky_cond_nonceil_OVCT</th>\n",
       "      <th>sky_cond_nonceil_POBS</th>\n",
       "      <th>sky_cond_nonceil_SCAT</th>\n",
       "      <th>sky_cond_nonceil_UNK</th>\n",
       "      <th>wx_int_precip_LGT</th>\n",
       "      <th>wx_int_precip_LT</th>\n",
       "      <th>wx_int_precip_MOD</th>\n",
       "      <th>wx_int_precip_UNK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cert_max_gr_wt  afm_hrs_last_insp  rwy_len  rwy_width  inj_f_grnd  \\\n",
       "0        750000.0              113.0  11800.0      150.0         0.0   \n",
       "1          3800.0               49.0   2610.0       40.0         0.0   \n",
       "2         14100.0                3.0   5500.0      100.0         0.0   \n",
       "3          6000.0               13.0   3800.0       36.0         0.0   \n",
       "4           900.0               10.0   1900.0       75.0         0.0   \n",
       "\n",
       "   inj_m_grnd  inj_s_grnd  Total_Fatal_Injuries  Total_Minor_Injuries  \\\n",
       "0         0.0         0.0                   0.0                   0.0   \n",
       "1         0.0         0.0                   0.0                   0.0   \n",
       "2         0.0         0.0                   2.0                   0.0   \n",
       "3         0.0         0.0                   2.0                   0.0   \n",
       "4         0.0         0.0                   0.0                   0.0   \n",
       "\n",
       "   Total_Uninjured  ...  sky_cond_nonceil_CLER  sky_cond_nonceil_FEW  \\\n",
       "0              4.0  ...                      0                     0   \n",
       "1              1.0  ...                      0                     0   \n",
       "2              0.0  ...                      0                     0   \n",
       "3              0.0  ...                      1                     0   \n",
       "4              1.0  ...                      0                     0   \n",
       "\n",
       "   sky_cond_nonceil_OVCT  sky_cond_nonceil_POBS  sky_cond_nonceil_SCAT  \\\n",
       "0                      0                      0                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      1                      0                      0   \n",
       "\n",
       "   sky_cond_nonceil_UNK  wx_int_precip_LGT  wx_int_precip_LT  \\\n",
       "0                     0                  0                 0   \n",
       "1                     1                  0                 0   \n",
       "2                     1                  0                 0   \n",
       "3                     0                  0                 0   \n",
       "4                     0                  0                 0   \n",
       "\n",
       "   wx_int_precip_MOD  wx_int_precip_UNK  \n",
       "0                  0                  1  \n",
       "1                  0                  1  \n",
       "2                  1                  0  \n",
       "3                  0                  1  \n",
       "4                  0                  1  \n",
       "\n",
       "[5 rows x 17992 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b2d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_X = phase_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0ae712b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 0, ..., 4, 6, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "LE.fit(phase_y)\n",
    "phase_y = LE.transform(phase_y)\n",
    "phase_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0484169c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.500e+05, 1.130e+02, 1.180e+04, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.800e+03, 4.900e+01, 2.610e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [1.410e+04, 3.000e+00, 5.500e+03, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.320e+03, 1.000e+00, 6.000e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [1.450e+03, 4.400e+01, 4.000e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.190e+03, 6.500e+01, 6.143e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8ca20",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "cv = StratifiedShuffleSplit(n_splits=1,test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4e58b",
   "metadata": {},
   "source": [
    "Random forrest grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "749622a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.57162695        nan 0.5621993 ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.92 s, sys: 7.13 s, total: 12.1 s\n",
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=6,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': ['None', 10], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2], 'n_estimators': [10],\n",
       "                         'random_state': [42]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#run random forest on cancellations with grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_can_rf = RandomForestClassifier()\n",
    "\n",
    "can_rf_params = {'n_estimators':[10,20,30],\n",
    "                   'max_depth': ['None', 10,20,20],\n",
    "                   'criterion': ['gini', 'entropy'],\n",
    "                   'min_samples_split': [2,3],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'random_state': [42]\n",
    "                  }\n",
    "\n",
    "can_rf_grid = GridSearchCV(estimator = clf_can_rf,\n",
    "                               n_jobs = 6,\n",
    "                               verbose = 1,\n",
    "                               param_grid = can_rf_params,\n",
    "                               cv = 2,\n",
    "                               scoring = 'accuracy')\n",
    "\n",
    "can_rf_grid.fit(inj_X,inj_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02ec84e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da086f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#run random forest on cancellations with grid search - undersampled data\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_can_rf = RandomForestClassifier(class_weight = 'balanced')\n",
    "\n",
    "can_rf_params = {'n_estimators':[20, 50, 100],\n",
    "                   'max_depth': [10, 20, 100, 200],\n",
    "                   'criterion': ['gini', 'entropy'],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'min_samples_leaf': [1, 2, 5, 10],\n",
    "                   'random_state': [13]\n",
    "                  }\n",
    "\n",
    "can_rf_grid = GridSearchCV(estimator = clf_can_rf,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 1,\n",
    "                               param_grid = can_rf_params,\n",
    "                               cv = 10,\n",
    "                               scoring = 'accuracy')\n",
    "\n",
    "can_rf_grid.fit(X_train_can_under,y_train_can_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec820a28",
   "metadata": {},
   "source": [
    "#### Logistic Regression for predicting `Injury`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "import time\n",
    "lr_clf = LogisticRegression(solver='liblinear', penalty=\"l2\",max_iter=1000,random_state=42)\n",
    "iter_num=0\n",
    "for train_indices, test_indices in cv.split(inj_X,inj_y): \n",
    "#     start = time.time()\n",
    "#     elapsed_time = (time.time() - start)\n",
    "    X_train = inj_X[train_indices]\n",
    "    y_train = inj_y[train_indices]\n",
    "    \n",
    "    X_test = inj_X[test_indices]\n",
    "    y_test = inj_y[test_indices]\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "#     print(conf )\n",
    "#     print('CV Time: ', elapsed_time)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cd4b2",
   "metadata": {},
   "source": [
    "#### Logistic Regression for predicting `phase_flt_spec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d68c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "import time\n",
    "lr_phase = LogisticRegression(solver='liblinear', penalty=\"l2\",max_iter=1000,random_state=42)\n",
    "# scl_obj = StandardScaler()\n",
    "# scl_obj.fit(X_train)\n",
    "iter_num=0\n",
    "for train_indices, test_indices in cv.split(phase_X,phase_y): \n",
    "    X_train = phase_X[train_indices]\n",
    "    y_train = phase_y[train_indices]\n",
    "    \n",
    "    X_test = phase_X[test_indices]\n",
    "    y_test = phase_y[test_indices]\n",
    "#     scl_obj.fit(X_train)\n",
    "#     X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "#     X_test_scaled = scl_obj.transform(X_test)\n",
    "    lr_phase.fit(X_train,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_phase.predict(X_test) # get test set predictions\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e3351",
   "metadata": {},
   "source": [
    "### KNN classifier\n",
    "The KNN algorithm assumes that similar things exist in proximity. It can be used as a classifier to implement the k-nearest neighbors. KNN is used to make predictions. For our dataset, we will be using KNN to predict injury. Our datatest was scaled since KNN classifier requires that. We will be using stratified k-fold cross-validation because with this the mean response value is approximately equal in all the folds. Each test fold has equal class labels. For the KNN classifier, our evaluation metrics will be the accuracy, precision, AUC.\n",
    "\n",
    "#### Accuracy\n",
    "This will be used to predict which model performs better at prediction. This will be an important metric in predicting an injury. \n",
    "$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "#### Precision\n",
    "Precision is the ratio between the True Positives and all the Positives. For our classification, it would be a measure of accidents that could lead to an injury.\n",
    "$Precision = \\frac{TP}{PP}$\n",
    "\n",
    "#### Area under the Curve\n",
    "AUC will measure the performance of our classification problem at different thresholds. The AUC model will be used to evaluate which model is accurate. The closer the model to 1, the more it is a good model to distinguish between negative and positive scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def InjuryEvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, inj_X, inj_y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def PhaseEvaluateClassifierEstimator(classifierEstimator, phase_X, phase_y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, phase_X, phase_y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat = np.zeros(inj_y.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "#cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "for train, test in cv.split(inj_X,inj_y):\n",
    "    clf.fit(inj_X[train],inj_y[train])\n",
    "    yhat[test] = clf.predict(inj_X[test])\n",
    "\n",
    "total_accuracy = mt.accuracy_score(inj_y, yhat)\n",
    "print ('KNN accuracy', total_accuracy)\n",
    "total_precision = mt.precision_score(inj_y, yhat)\n",
    "print ('KNN precision', total_precision)\n",
    "total_confusion_matrix = mt.confusion_matrix(inj_y, yhat)\n",
    "print ('KNN confusion_matrix', total_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateClassifierEstimator(clf, inj_X, inj_y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42779118",
   "metadata": {},
   "source": [
    "We had an accuracy of about 71.6%. We will try k=5 to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat = np.zeros(y.shape) # we will fill this with predictions\n",
    "\n",
    "# create cross validation iterator\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "for train, test in cv.split(X,y):\n",
    "    clf.fit(X[train],y[train])\n",
    "    yhat[test] = clf.predict(X[test])\n",
    "\n",
    "total_accuracy = mt.accuracy_score(y, yhat)\n",
    "print ('KNN accuracy', total_accuracy)\n",
    "total_precision = mt.precision_score(y, yhat)\n",
    "print ('KNN precision', total_precision)\n",
    "total_confusion_matrix = mt.confusion_matrix(y, yhat)\n",
    "print ('KNN confusion_matrix', total_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "We had an accuracy of 72% for k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(total_confusion_matrix, annot=True, fmt = \"d\", cmap=\"Spectral\"); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('ACTUAL LABELS');ax.set_ylabel('PREDICTED LABELS'); \n",
    "ax.set_title('KNN Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['11', '12','13','21','22','23','31','32','33']); ax.yaxis.set_ticklabels(['Soft', 'Tough']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accuracy(ytrue,yhat):\n",
    "    conf = mt.confusion_matrix(ytrue,yhat)\n",
    "    norm_conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    return np.diag(norm_conf)\n",
    "\n",
    "def plot_class_acc(ytrue,yhat, title=''):\n",
    "    acc_list = per_class_accuracy(ytrue,yhat)\n",
    "    plt.bar(range(len(acc_list)), acc_list)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.title(title+\", Total Acc=%.1f\"%(100*mt.accuracy_score(ytrue,yhat)))\n",
    "    plt.grid()\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_class_acc(y,yhat,title=\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a3cbc1",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "We will plot the ROC curve which is a plot of True Positive Rate vs False Positive Rate. The AUC-ROC will help us visualize how well our KNN classifier is performing. For our dataset, We save the outputs into a dictionary of fpr and tpr (false positive and true positive rates). The keys to the dictionary are the class value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_scores = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d242639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d91599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform hyperparameter search to find the best k value\n",
    "param_grid = {'n_neighbors':np.arange(1,21)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=10)\n",
    "knn_cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will try the roc curve with new k value\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors = 20)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_scores = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a8dbc",
   "metadata": {},
   "source": [
    "We had a better AUC score of 86% with k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9a44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
